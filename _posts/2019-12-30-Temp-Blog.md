---
layout: zilfi
mathjax: true
title:  Shapley Value Regression
excerpt: Shapley value regression can deal with multicollinearity that is frequently encountered in marketing research that uses rating scale data. The article studies Shapley Value decomposition from the game theory as a method of discovering the relative importance of predictors in order to understand the key drivers of successful restaurant business.
keywords: shapley value, multicollinearity, relative importance, r programming
---


Summary
=======

Here is the `summary`

Introduction
============

Inline forula: $H_0:\beta = 0$

Data description
================

{% highlight ruby %}
# load the required libraries used in the article
if (!require("pacman")) install.packages("pacman")
pacman::p_load(dplyr, readxl, knitr, kableExtra, networkD3, ggcorrplot, 
               stringr, radiant.data, textshape, formattable, RColorBrewer, ggraph, igraph)
{% endhighlight %}

The plot above shows the correlation between the drivers of target 2.
Similarly, there are high correlations between all pairs of variables.
The highest correlation is between the variables `Menu by norms`
(restaurant modifies menu items driven by regulatory norms) and
`Various segments` (restaurant works for various customer segments).

The share of the regressor variable $x_i$ for a given set of $k$
predictor variables is given by the following formula:

$$ S({x_i})=\dfrac {1} {k} \sum_{r=1}^{k}\dfrac {\sum_{c=1}^{l}(R^2_{(i,r)}-R^2_{(j,r-1)})_c} {l} $$

$$ S({x_i})=\dfrac {1} {k} \sum_{r=1}^{k}\dfrac {\sum_{c=1}^{l}(R^2_{(i,r)}-R^2_{(j,r-1)})c} {l} $$

where

-   $k$ is the number of regressor variables in the multiple linear
    regression model
-   $R^2_{(i,r)}$ obtained from the model where the regressors are an
    r-membered subset of all possible regressors with $i^{th}$ variable
-   $R^2_{(j,r-1)}$ obtained from the model where the regressors are an
    r-membered subset of all possible regressors without $i^{th}$
    variable.

Thus we will have the following weighted Shapley value for the variable
$x_1$:

$$SV_{x_1} = \dfrac{1}{3}(R^2_{x_1}-R^2_{\beta_0})+\dfrac{1}{6}(R^2_{x_1;x_2}-R^2_{x_2}) + \dfrac{1}{6}(R^2_{x_1;x_3}-R^2_{x_3}) + \dfrac{1}{3}(R^2_{x_1;x_2;x_3}-R^2_{x_2;x_3})$$

~~~ r
plot(mtcars$mpg)
~~~

![](/2019-12-30-Temp-Blog_files/figure-markdown/unnamed-chunk-2-1.png)


<img src="/2019-12-20-Shapley-value-regression_files/figure-markdown/causalgraph-1.png" width="75%" />

Reference List
==============

> Mishra, S.K. (2016) ?Shapley value regression and the resolution of
> multicollinearity?, MPRA, (72116). Available at:
> <https://mpra.ub.uni-muenchen.de/72116/>. Lipovetsky, S. (2006)
> ?Entropy Criterion In Logistic Regression And Shapley Value Of
> Predictors?, Journal of modern applied statistical methods: JMASM, 5,
> pp.Â 95?106. doi: 10.22237/jmasm/1146456480.

> Hart S. (1989) Shapley Value. In: Eatwell J., Milgate M., Newman P.
> (eds) Game Theory. The New Palgrave. Palgrave Macmillan, London
